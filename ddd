import requests
import pandas as pd
from bs4 import BeautifulSoup
#import mysql.connector
import time
import random
import mysql.connector

mydb = mysql.connector.connect(
  host="rds-mysql-histvols.cfz6xe0w4pvt.us-east-1.rds.amazonaws.com",
  user="ejupsem",
  passwd="lie19Paj.a",
  database="ejupsem"
)

cursor = mydb.cursor(dictionary=True,buffered = True)


##Indian website
#Base_url= ("http://www.moneycontrol.com/company-facts/marutisuzukiindia/board-meetings/MS24#MS24")
##Base_url2= ("http://www.vegasinsider.com/nfl/odds/las-vegas/")
#page = requests.get(Base_url)
#page.status_code
#page.content
#
#soup = BeautifulSoup(page.content, 'html.parser')
#print(soup.prettify())
#
#table_it = soup.find_all('table', class_='tbldivid')
#print(table_it)
#
#date_list = []
#event_list = []
#for mytable in table_it:
#    #try:
#    rows = mytable.find_all('tr')
#    for tr in rows:
#        cols = tr.find_all('td')
#        for count, i in enumerate(cols):
#            er = i.text
#            ee = er.encode('utf8')
#            ee = str(ee)
#            
#            if count % 2 == 0:
#                date_list.append(ee)
#                
#            if count % 2 == 1:
#                event_list.append(ee)
#                    
#   # except:
#    #    print("no thead")
#
#print(date_list)
#print(event_list)
#
#df = pd.DataFrame({'Meeting Date': date_list, 'Remark': event_list,})
#df = df.loc[df['Remark'].isin(['Quarterly Results','Audited Results & Dividend'])]
#df_5 = df.head(16)
#print(df_5)


#try Zachs
#Base_url= ("https://www.zacks.com/earnings/earnings-calendar")
#page = requests.get(Base_url)
#page.status_code
#page.content
#
#soup = BeautifulSoup(page.content, 'html.parser')
#print(soup.prettify())
#
#table_it = soup.find_all('table', class_='tbldivid')
#print(table_it)
#
#date_list = []
#event_list = []
#for mytable in table_it:
#    #try:
#    rows = mytable.find_all('tr')
#    for tr in rows:
#        cols = tr.find_all('td')
#        for count, i in enumerate(cols):
#            er = i.text
#            ee = er.encode('utf8')
#            ee = str(ee)
#            
#            if count % 2 == 0:
#                date_list.append(ee)
#                
#            if count % 2 == 1:
#                event_list.append(ee)
#                    
#   # except:
#    #    print("no thead")
#
#print(date_list)
#print(event_list)
#
#df = pd.DataFrame({'Meeting Date': date_list, 'Remark': event_list,})
#df = df.loc[df['Remark'].isin(['Quarterly Results','Audited Results & Dividend'])]
#df_5 = df.head(16)
#print(df_5)

#for x in range(10):
#  print random.randint(1,8)
#  wait = random.randint(1,8)
#  time.sleep(wait)

year = ['2013','2014','2015','2016','2017','2017','2018']
months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct','Nov','Dec']
EarnTable = pd.DataFrame(columns = [['Name','Date']])
broke = pd.DataFrame(columns = [['Date']])

#https://www.nasdaq.com/earnings/earnings-calendar.aspx?date=2012-Dec-31
#NasdaqEarnings
for a in range(len(year)):
    for b in range(len(months)):
        for c in range(1,32):
            try:
#                #b=6
#                a=6
#                url = "https://www.nasdaq.com/earnings/earnings-calendar.aspx?date={}-{}-{}".format(year[a],months[b],c)
#                Base_url= (url)
#                print(url)
#                wait = random.randint(1,110)
#                print(wait)
#                time.sleep(wait)
#                page = requests.get(Base_url)
#                soup = BeautifulSoup(page.content, 'html.parser')
#                soup = str(soup)
#                loc = '/Users/ejupsem/Documents/Financial Data/EarnDates/NDQ_html{}{}{}.txt'.format(year[a],months[b],c)
#                f = open(loc,'w')
#                f.write(soup)
#                f.close()
                f = open('/Users/ejupsem/Documents/Financial Data/EarnDates/NDQ_html{}{}{}.txt'.format(year[a],months[b],c),'r')
                soup = f.read()
                f.close()
                soup = BeautifulSoup(soup, 'html.parser')

                table_it = soup.find_all('table')
                table_it = table_it[0]
                rows = table_it.find_all('tr')
                for count in range(1,len(rows)):
                    test = rows[count]
                    suite = test.find_all('td')
                    element = suite[1]
                    element = str(element)
                    element = element[::-1]
                    start = element.find(')')+1
                    end = element.find('(')
                    if end == -1 or start == -1:
                        insert2 = pd.DataFrame(['{}{}{}'.format(year[a],months[b],c)],columns = ['Date'])
                        broke = broke.append(insert2).reset_index(drop=True)
                        break
                    Name = element[start:end]
                    Name = Name[::-1]
                
                    fuck2 = str(suite[2])
                    start =  fuck2.find('/')
                    Date = fuck2[start-2:start+8]
                    
                    insert = pd.DataFrame([[Name,Date]],columns = ['Name','Date'])
                    EarnTable = EarnTable.append(insert).reset_index(drop=True)
            except:
                print("shit broke")
                pass
            
#f = open('/Users/ejupsem/Downloads/test_hello_world2.txt','r')
#message = f.read()
#print(message)
#f.close()
#soup = BeautifulSoup(message, 'html.parser')
#table_it = soup.find_all('table')
#table_it = table_it[0]
#rows = table_it.find_all('tr')
#for count in range(1,len(rows)):
#    #cols = tr.find_all('td')
#    #for count, i in range(1,len(cols):
#    test = rows[count]
#    suite = test.find_all('td')
#    element = suite[1]
#    element = str(test)
#    fuck1 = element.count(')')
#    element = element[::-1]
#    start = element.find(')')+1
#    end = element.find('(')
#    Name = element[start:end]
#    Name = Name[::-1]
#
#    fuck2 = str(suite[2])
#    start =  fuck2.find('/')
#    Date = fuck2[start-2:start+8]
#    print(pd.DataFrame([[Name,Date]],columns = ['Name','Date']))

#AllEarn = pd.read_csv('/Users/ejupsem/Documents/incompleteEarn.csv')
#StockKeys = pd.read_sql_query('Select * from StockKeys',mydb)
#asdf = AllEarn.merge(StockKeys,how='left',on='Name')

#error = asdf[asdf['SecurityID'].isnull()]

r = EarnTable['Date'].str.split("/",expand = True)
r.columns = ['Month','Day','Year']
r['Year'] = r['Year'].astype(int)
r['Month'] = r['Month'].astype(int)
r['Day'] = r['Day'].astype(int)
r['Date'] = r['Year'] * 10000 + r['Month'] * 100 + r['Day']
EarnTable['Date2'] = r['Date']
    
